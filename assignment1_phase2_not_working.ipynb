{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1_phase2_not_working.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTAi6CEgf7vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.applications import vgg16\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from skimage.transform import resize\n",
        "from keras.optimizers import adam\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8_JG-F_CSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6xX229g3iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 2\n",
        "NUM_EPOCHS = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nwp2YPag30m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_arr is of shape (n, h, w, c)\n",
        "def resize_image_arr(img_arr):\n",
        "    x_resized_list = []\n",
        "    for i in range(img_arr.shape[0]):\n",
        "        img = img_arr[0]\n",
        "        resized_img = resize(img, (224, 224))\n",
        "        x_resized_list.append(resized_img)\n",
        "    return np.stack(x_resized_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KU666YNg4A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train[0:1000]\n",
        "y_train = y_train[0:1000]\n",
        "x_test = x_test[0:1000]\n",
        "y_test = y_test[0:1000]\n",
        "\n",
        "# Resize image arrays\n",
        "x_train = resize_image_arr(x_train)\n",
        "x_test = resize_image_arr(x_test)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvASWfO4g4OU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5633fd41-6624-4229-bdc7-c1ef0c057da1"
      },
      "source": [
        "base_model = vgg16.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- 10 classes for CIFAR10\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "#opt = keras.optimizers.rmsprop(lr=0.0, decay=0.0)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1l5wWivQQ5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "69c177e8-7e08-4776-d68f-cf59dbacea12"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 14,982,474\n",
            "Trainable params: 14,982,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfOI7Mq1_ngL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "faedca27-ef33-41de-90c1-9164006f06bf"
      },
      "source": [
        "model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 10, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=10)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "390/390 [==============================] - 65s 167ms/step - loss: 0.2766 - acc: 0.9004 - val_loss: 0.2505 - val_acc: 0.9005\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 59s 152ms/step - loss: 0.2167 - acc: 0.9128 - val_loss: 0.1754 - val_acc: 0.9323\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.1676 - acc: 0.9361 - val_loss: 0.1514 - val_acc: 0.9415\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.1348 - acc: 0.9489 - val_loss: 0.1298 - val_acc: 0.9520\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.1128 - acc: 0.9580 - val_loss: 0.1159 - val_acc: 0.9572\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.0965 - acc: 0.9646 - val_loss: 0.1142 - val_acc: 0.9597\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.0833 - acc: 0.9697 - val_loss: 0.1094 - val_acc: 0.9610\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.0726 - acc: 0.9736 - val_loss: 0.1116 - val_acc: 0.9617\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.0659 - acc: 0.9760 - val_loss: 0.1116 - val_acc: 0.9623\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 58s 149ms/step - loss: 0.0587 - acc: 0.9791 - val_loss: 0.1159 - val_acc: 0.9623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdafe60a2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gak2ZA6sxMkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10cySL4EqgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12269166-d03a-419a-cc6b-89d6bed9aca0"
      },
      "source": [
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is: 79.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu7vebABEzLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict(test_features)\n",
        "predicted_classes = np.argmax(predicted,axis=1)\n",
        "predicted_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoJ_0ca_FLgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_classes = np.argmax(test_labels,axis=1)\n",
        "true_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8RCOeBAFX4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa076b49-039d-4ac0-8eea-1ac3d1ec46d6"
      },
      "source": [
        "count=0\n",
        "image_index=list()\n",
        "for i in range(len(true_classes)):\n",
        "  if predicted_classes[i] != true_classes[i]:\n",
        "    image_index.append(i)\n",
        "    count+=1\n",
        "print(\"Total number of missclassified images : \",count)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of missclassified images :  2449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50uFM0aWFl8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHyGzr8Ftnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = {0:'airplane', \n",
        "          1:'automobile',\n",
        "          2:'bird',\n",
        "          3:'cat',\n",
        "          4:'deer',\n",
        "          5:'dog',\n",
        "          6:'frog',\n",
        "          7:'horse',\n",
        "          8:'ship',\n",
        "          9:'truck'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z4oFBXtFxaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e56d9a6-6525-4c22-e9ec-f447935e45d2"
      },
      "source": [
        "for i in range(50):\n",
        "  true_label = true_classes[image_index[i]]\n",
        "  predicted_label = predicted_classes[image_index[i]]\n",
        "  testimage1 = test_features[image_index[i]]\n",
        "  testimage1 = cv2.resize(testimage1, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "  x = image.img_to_array(testimage1)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  \n",
        "  preds = model.predict(x)\n",
        "  class_idx = np.argmax(preds[0])\n",
        "#   print(class_idx)\n",
        "  class_output =model.output[:, class_idx]\n",
        "  last_conv_layer = model.get_layer(\"res5c_branch2c\")\n",
        "  \n",
        "  grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "#   print(grads.shape)\n",
        "  pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "#   print(pooled_grads.shape)\n",
        "  iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "  pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "  for i in range(512):\n",
        "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "    \n",
        "  heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "#   print(conv_layer_output_value.shape)\n",
        "#   print(heatmap.shape)\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  try:\n",
        "    heatmap /= np.max(heatmap)\n",
        "  except:\n",
        "    print('Can not divided by NaN')\n",
        "  heatmap = cv2.resize(heatmap, (testimage1.shape[1], testimage1.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  \n",
        "  superimposed_img = cv2.addWeighted(testimage1, 0.5, heatmap, 0.5,0,dtype=cv2.CV_32F)\n",
        "  print('True Label : ',labels[true_label])\n",
        "  print('Predicted Label : ',labels[predicted_label])\n",
        "  cv2_imshow(testimage1)\n",
        "  cv2_imshow(superimposed_img)\n",
        "  print()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Label :  frog\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF817EF0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF7929B0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  dog\n",
            "Predicted Label :  deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF72C240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF885518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  deer\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF6BE6A0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF6BE748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  truck\n",
            "Predicted Label :  automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF652908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF6525F8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  deer\n",
            "Predicted Label :  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF5E99E8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF567CF8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  bird\n",
            "Predicted Label :  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF4FFB70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF47CF28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  deer\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF47CF28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF47CF98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  dog\n",
            "Predicted Label :  cat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF4FFA20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF420C18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  truck\n",
            "Predicted Label :  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF410EF0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF33CDA0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  airplane\n",
            "Predicted Label :  horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF258A20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF47CF98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  horse\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF33CDA0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF1708D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  deer\n",
            "Predicted Label :  cat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF2586D8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF170860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  frog\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF2D9EF0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF0A3B38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  cat\n",
            "Predicted Label :  dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFEFBEC88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFF038DD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True Label :  airplane\n",
            "Predicted Label :  automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFEF57EB8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKElEQVR4nO3NMQEAAAjDsIF/0Zhg\nXyqgmWTTrHsHAAAAAAAAAAAAjx2oaQBC1clCDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FDAFEF57EB8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-8d44c2578834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0miterate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpooled_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mpooled_grads_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer_output_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9rQw7qIF0Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}